{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b8c75f4",
   "metadata": {},
   "source": [
    "### 4. Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3ecd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Word2Vec model from gensim, which is used for learning word embeddings\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4581ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a small dataset where each sentence is a list of words\n",
    "sentences = [\n",
    "    [\"artificial\", \"intelligence\", \"is\", \"cool\"],\n",
    "    [\"machine\", \"learning\", \"is\", \"fun\"],\n",
    "    [\"ai\", \"learning\", \"uses\", \"neural\", \"networks\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d421ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Word2Vec model on the sentences\n",
    "model = Word2Vec(\n",
    "    sentences, \n",
    "    vector_size=10,  # Each word will be represented by a 10-dimensional vector\n",
    "    window=2,        # Context window size is 2 (words before and after)\n",
    "    min_count=1,     # Include words that appear at least once\n",
    "    sg=1             # Use skip-gram algorithm (good for small datasets)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03aeaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'learning': [-0.00537069  0.00235848  0.05102572  0.09009185 -0.09303681 -0.07116417\n",
      "  0.06458981  0.08972324 -0.05014562 -0.03762919]\n",
      "Most similar to 'learning': [('is', 0.5435845851898193), ('artificial', 0.43179193139076233), ('cool', 0.3793115019798279), ('networks', 0.30033737421035767), ('neural', 0.10495670884847641), ('machine', -0.13116095960140228), ('fun', -0.18973511457443237), ('uses', -0.22416219115257263), ('ai', -0.2725953757762909), ('intelligence', -0.728771984577179)]\n"
     ]
    }
   ],
   "source": [
    "# Print the vector representation for the word 'learning'\n",
    "print(\"Vector for 'learning':\", model.wv['learning'])\n",
    "\n",
    "# Print the words most similar to 'learning' according to the trained model\n",
    "print(\"Most similar to 'learning':\", model.wv.most_similar('learning'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a59aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
