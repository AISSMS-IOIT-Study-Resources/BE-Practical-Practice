{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f697c776",
   "metadata": {},
   "source": [
    "### Implementing Retrieval-Augmented Generation (RAG) with FAISS and a Pre-trained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492f37d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Academics\\Aissms\\B.Tech.Docs\\Sem-7\\Practical\\GenAi\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np \n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13bf1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(embeddings):\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(embeddings.astype('float32'))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_generate(query, doc_embeddings, query_embedding, texts, model_name='distilgpt2'):\n",
    "    index = build_index(doc_embeddings)\n",
    "    D, I = index.search(query_embedding.astype('float32').reshape(1, -1), 3)\n",
    "    retrieved = [texts[i] for i in I[0]]\n",
    "    context = '\\n'.join(retrieved)\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    \n",
    "    gen = pipeline('text-generation', model=model_name, tokenizer=model_name)\n",
    "    out = gen(prompt, max_length=50)[0]['generated_text']\n",
    "\n",
    "    if \"Answer:\" in out:\n",
    "        answer_part = out.split(\"Answer:\", 1)[1].strip()\n",
    "        answer = answer_part.split('\\n')[0].strip()\n",
    "    else:\n",
    "        answer = out\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad185aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"Dogs are loyal animals.\",\n",
    "    \"Machine learning is a subset of AI.\",\n",
    "    \"Python is a programming language.\",\n",
    "    \"FAISS is a library for similarity search.\"\n",
    "]\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "doc_embeddings = model.encode(texts)\n",
    "\n",
    "# Query\n",
    "query = \"What is machine learning?\"\n",
    "query_embedding = model.encode([query])[0]\n",
    "\n",
    "# Generate answer\n",
    "answer = retrieve_and_generate(query, doc_embeddings, query_embedding, texts)\n",
    "print(\"Query:\", query)\n",
    "print(\"Answer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
