{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3be8001",
   "metadata": {},
   "source": [
    "### Implementing Word Embeddings and Semantic Similarity Search using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7cd369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a348b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus():\n",
    "    corpus = [\n",
    "        \"The quick brown fox jumps over the lazy dog\",\n",
    "        \"I love natural language processing and machine learning\",\n",
    "        \"Word embeddings help capture semantic relationships\",\n",
    "        \"The fox is clever and quick\",\n",
    "        \"Dogs are loyal and friendly animals\",\n",
    "        \"Machine learning models improve with more data\"\n",
    "    ]\n",
    "    tokenized = [simple_preprocess(doc) for doc in corpus]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c99e6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec(tokenized_corpus, vector_size=50, window=3, min_count=1):\n",
    "    model = Word2Vec(\n",
    "        sentences=tokenized_corpus, \n",
    "        vector_size=vector_size, \n",
    "        window=window, \n",
    "        min_count=min_count, \n",
    "        workers=1, \n",
    "        seed=42 \n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a9ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(word_vectors):\n",
    "    dim = word_vectors.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(word_vectors)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5376af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_similar_words(model, index, word, top_k=5):\n",
    "    if word not in model.wv:\n",
    "        print(f\"Word '{word}' not in vocabulary.\")\n",
    "        return\n",
    "    \n",
    "    query_vec = model.wv[word].reshape(1, -1).astype(np.float32)\n",
    "    distances, indices = index.search(query_vec, top_k + 1)\n",
    "\n",
    "    print(f\"\\nTop {top_k} words similar to '{word}':\")\n",
    "    for dist, idx in zip(distances[0][1:], indices[0][1:]):\n",
    "        similar_word = model.wv.index_to_key[idx]\n",
    "        print(f\" {similar_word} (distance: {dist:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8e050af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    tokenized_corpus = load_corpus()\n",
    "    print(\"Tokenized corpus: \")\n",
    "    for sent in tokenized_corpus:\n",
    "        print(sent)\n",
    "    \n",
    "    model = train_word2vec(tokenized_corpus)\n",
    "    word_vectors = model.wv.vectors.astype(np.float32)\n",
    "\n",
    "    faiss_index = build_faiss_index(word_vectors)\n",
    "    query_words = ['fox', 'machine', 'dog', 'language', 'quick']\n",
    "\n",
    "    for word in query_words:\n",
    "        query_similar_words(model, faiss_index, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4bfb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized corpus: \n",
      "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "['love', 'natural', 'language', 'processing', 'and', 'machine', 'learning']\n",
      "['word', 'embeddings', 'help', 'capture', 'semantic', 'relationships']\n",
      "['the', 'fox', 'is', 'clever', 'and', 'quick']\n",
      "['dogs', 'are', 'loyal', 'and', 'friendly', 'animals']\n",
      "['machine', 'learning', 'models', 'improve', 'with', 'more', 'data']\n",
      "\n",
      "Top 5 words similar to 'fox':\n",
      " love (distance: 0.0068)\n",
      " and (distance: 0.0092)\n",
      " language (distance: 0.0092)\n",
      " quick (distance: 0.0095)\n",
      " semantic (distance: 0.0095)\n",
      "\n",
      "Top 5 words similar to 'machine':\n",
      " capture (distance: 0.0088)\n",
      " clever (distance: 0.0090)\n",
      " loyal (distance: 0.0096)\n",
      " language (distance: 0.0099)\n",
      " are (distance: 0.0101)\n",
      "\n",
      "Top 5 words similar to 'dog':\n",
      " love (distance: 0.0090)\n",
      " capture (distance: 0.0101)\n",
      " machine (distance: 0.0108)\n",
      " loyal (distance: 0.0112)\n",
      " clever (distance: 0.0116)\n",
      "\n",
      "Top 5 words similar to 'language':\n",
      " love (distance: 0.0079)\n",
      " and (distance: 0.0088)\n",
      " semantic (distance: 0.0091)\n",
      " fox (distance: 0.0092)\n",
      " relationships (distance: 0.0095)\n",
      "\n",
      "Top 5 words similar to 'quick':\n",
      " capture (distance: 0.0085)\n",
      " love (distance: 0.0095)\n",
      " fox (distance: 0.0095)\n",
      " semantic (distance: 0.0102)\n",
      " machine (distance: 0.0106)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871b089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
